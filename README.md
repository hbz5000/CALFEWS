# California Food-Energy-Water System (CALFEWS)
For general information on the California Food-Energy-Water System (CALFEWS) simulation model, please switch to the "main" branch of this repository, where you will find information on installing, compiling, running, and analyzing the base model. Interested readers can also refer to the following paper to learn more about the performance and conceptual underpinnings of the model:

Zeff, H.B., Hamilton, A.L., Malek, K., Herman, J.D., Cohen, J.S., Medellin-Azuara, J., Reed, P.M., and G.W. Characklis. (2021). California's Food-Energy-Water System: An Open Source Simulation Model of Adaptive Surface and Groundwater Management in the Central Valley. *Environmental Modelling & Software, 141*: 105052. [https://doi.org/10.1016/j.envsoft.2021.105052](https://doi.org/10.1016/j.envsoft.2021.105052) 

Licensed under the MIT License, 2017-2022.

## Infrastructure partnership design experiment
This "FKC_experiment_longleaf" branch of the repository contains code and data for the following paper:

Hamilton, A.L., Zeff, H.B., Characklis, G.W., & P.M. Reed. (2022). Resilient California water portfolios require infrastructure investment partnerships that are viable for all partners. (In review, [pre-print available](https://www.essoar.org/doi/10.1002/essoar.10508968.2)).

Download the exact version used to produce the paper at [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4091708.svg)](https://doi.org/10.5281/zenodo.4091708).

**Abstract**
> Water scarcity is a growing problem around the world, and regions such as California are working to develop diversified, interconnected, and flexible water supply portfolios. To meet their resilient water portfolio goals, water utilities and irrigation districts will need to cooperate across scales to finance, build, and operate shared water supply infrastructure. However, planning studies to date have generally focused on partnership-level outcomes (i.e., highly aggregated mean cost-benefit analyses), while ignoring the heterogeneity of benefits, costs, and risks across the individual investing partners. This study contributes an exploratory modeling analysis that tests thousands of alternative water supply investment partnerships in the Central Valley of California, using a high-resolution simulation model to evaluate the effects of new infrastructure on individual water providers. The viability of conveyance and groundwater banking investments are as strongly shaped by partnership design choices (i.e., which water providers are participating, and how do they distribute the projectâ€™s debt obligation?) as by extreme hydrologic conditions (i.e., floods and droughts). Importantly, most of the analyzed partnership structures yield highly unequal distributions of water supply and financial risks across the partners, limiting the viability of cooperative partnerships. Partnership viability is especially rare in the absence of groundwater banking facilities, or under dry hydrologic conditions, even under explicitly optimistic assumptions regarding climate change. These results emphasize the importance of high-resolution simulation models and careful partnership structure design when developing resilient water supply portfolios for institutionally complex regions confronting scarcity.


## Installation and setup
1. First, switch to the "main" branch of this repository and follow instructions to clone, compile, and run the base CALFEWS model. If you only want to recreate the data analysis and figures (step 5), you can just setup CALFEWS on a local desktop/laptop. If you also want to recreate the full exploratory experiment (step 4), then you will need to access to a larger computing cluster, and should set up CALFEWS there as well.
2. Then switch back to this "FKC_experiment_longleaf" branch and rerun the cythonization command, ``python3 setup_cy.py build_ext --inplace``, on all machines. 
4. Run the exploratory experiment on your computing cluster. I used the [Longleaf Cluster](https://its.unc.edu/research-computing/longleaf-cluster/) at the University of North Carolina at Chapel Hill, which allowed me to run up to 800 cores simultaneously. 
    1. For each of the three \*.ini files in the "FKC_experiment/exploratory_experiment_scripts" directory, replace "/pine/scr/a/l/alh91/CALFEWS_results/" with the results directory where you want your results to be stored. Make sure this directory exists.  Then move all files from the "FKC_experiment/exploratory_experiment_scripts" directory into the base CALFEWS directory, and move to the base directory from the command line. Note: Depending on your cluster, you may want both your base directory and your results directory to be on the "scratch" drive, rather than your home directory. 
    2. In "sbatch_single_longleaf.sh", change the "output" location to <results_dir>/FKC_experiment/outhere, where <results_dir> is the results directory from the last step. You will also need to alter the SBATCH directives to match your cluster's scheduler and change the loaded modules and Python virtual environment based on your particular setup.
    3. Launch experiment: ``sh run_sbatch_many.sh``. This will submit ~27,000 individual jobs to the slurm scheduler, each of which requests a single core to run a single simulation. If your cluster has a limit on the number of jobs you can have in the queue at once, you may need to split this up into smaller batches. Each simulation takes ~20-50 minutes, so at full utilization of the 800 cores this would take about 17 hours. However, in practice it took several days due to queueing time. Note: this will create a very large amount of data (~2.3 TB), broken into ~27,000 individual directories, so make sure you have sufficient space to handle this.
    4. Once all simulations have completed, postprocess to get objectives from each simulation: ``sh run_batch_objectives.sh``. This will launch 800 jobs to the slurm scheduler, each of which will calculate objectives for a subset of the simulations. You can change the 800 at the top to change how many chunks to break the processing into.
    5. Once all jobs have completed, run additional postprocessing: ``sh run_postprocess_objs.sh``. You will need to change the directory address at the top to match the location where your results are stored. This script will gather all the individual simulations' objectives into a single file, and calculate additional objective values.
    6. If you are working on a scratch directory subject to purge policies, make sure to move all results to a longer-term storage location.
5. Run the data analysis and create figures from paper. This can be done either on local machine or cluster.
    1. Copy "objs_clean.csv" to "FKC_experiment/output_data" directory, then move to the "FKC_experiment/analysis_and_figures_scripts" directory from the command line.
    2. 

